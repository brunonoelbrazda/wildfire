{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import json\n",
    "\n",
    "from datetime import timedelta \n",
    "from sklearn.metrics import pairwise\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Clustering Packages\n",
    "from sklearn import cluster\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from matplotlib import cm\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a31ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up connection using path of the SQLite Database\n",
    "connection = sqlite3.connect('/Users/brunonoelbrazda/Downloads/FPA_FOD_20170508.sqlite')\n",
    "\n",
    "query = '''\n",
    "        SELECT *\n",
    "        FROM Fires\n",
    "        '''\n",
    "\n",
    "df = sql.read_sql(query, con = connection)\n",
    "\n",
    "#importing the discovery and containted dates as datetime\n",
    "query = '''SELECT datetime(DISCOVERY_DATE) as DISCOVERY_DATE,\n",
    "datetime(CONT_DATE) as CONT_DATE FROM Fires;\n",
    "'''\n",
    "\n",
    "date = sql.read_sql(query, con = connection)\n",
    "date['DISCOVERY_DATE'] = pd.to_datetime(date.DISCOVERY_DATE)\n",
    "date['CONT_DATE']=pd.to_datetime(date.CONT_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fd399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the fire_size feature\n",
    "df['FIRE_SIZE'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb79d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that I didn't need for my model. \n",
    "# Primarily different Identifiers of Fires and Reporting Units\n",
    "df.drop(['FPA_ID','SOURCE_SYSTEM_TYPE','SOURCE_SYSTEM','NWCG_REPORTING_AGENCY',\n",
    "         'NWCG_REPORTING_UNIT_ID','NWCG_REPORTING_UNIT_NAME','SOURCE_REPORTING_UNIT',\n",
    "         'SOURCE_REPORTING_UNIT_NAME','LOCAL_FIRE_REPORT_ID','LOCAL_INCIDENT_ID',\n",
    "        'ICS_209_INCIDENT_NUMBER','ICS_209_NAME','MTBS_ID','Shape',\n",
    "        'FIRE_NAME','MTBS_FIRE_NAME','FIRE_CODE','COMPLEX_NAME','OBJECTID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eea136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dc8d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resampling weekly to see how mean fire size varies over the time frame\n",
    "s = df['FIRE_SIZE'].copy()\n",
    "date = pd.concat([date,s], axis=1)\n",
    "date = date.set_index('DISCOVERY_DATE').copy()\n",
    "date.resample('W').mean().plot(figsize=(8,8),kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c3af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting all the fires\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x='LONGITUDE',y='LATITUDE',data=df)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eddc450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Investingating where null values are in the data\n",
    "sns.heatmap(df.isnull(),cbar=False,cmap='crest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3383345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking out correlations\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df.corr(),cbar=True,annot=True,cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dda7fc",
   "metadata": {},
   "source": [
    "# (Testing) adding Weather Data using Virtual Crossing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2611d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the api\n",
    "\n",
    "url = \"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/40.03%2C-121.0/2005-2-2?unitGroup=metric&key=JLH8LVMM7G58T32S4BBCL4FWS&include=obs\"\n",
    "\n",
    "response = requests.request(\"GET\",url)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = json.loads(response.text)\n",
    "\n",
    "for i in response_dict:\n",
    "    print(\"key: \", i, \"val: \", response_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb4a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Humidity from the Dictionary\n",
    "print(response_dict['days'][0]['humidity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01343fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing making requests to the API using Python\n",
    "# Lat, Long extracted from their respective Features in the DataFrame\n",
    "# Year, Month, Day extracted from the DISCOVERY_DATE feature\n",
    "# Response from the API appended to a list\n",
    "humidity = []\n",
    "temps = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    lat = round(weather10['LATITUDE'][i],4)\n",
    "    long = round(weather10['LONGITUDE'][i],4)\n",
    "    date = weather10['DISCOVERY_DATE'][i].strftime(\"%Y-%m-%d\")\n",
    "    year = int(weather10['DISCOVERY_DATE'][i].strftime(\"%Y-%m-%d\")[0:4])\n",
    "    month = int(weather10['DISCOVERY_DATE'][i].strftime(\"%Y-%m-%d\")[5:7])\n",
    "    day = int(weather10['DISCOVERY_DATE'][i].strftime(\"%Y-%m-%d\")[8:10])\n",
    "    \n",
    "    \n",
    "    url = f'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{lat}%2C{long}/{year}-{month}-{day}?unitGroup=metric&key={apikey}&include=obs'\n",
    "\n",
    "    response = requests.request(\"GET\",url)\n",
    "    response_dict = json.loads(response.text)\n",
    "    temps.append(response_dict['days'][0]['temp'])\n",
    "    humidity.append(response_dict['days'][0]['humidity'])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b351bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = df[['LONGITUDE','LATITUDE','DISCOVERY_DATE']].copy()\n",
    "weather10 = weather.head(10).copy()\n",
    "weather10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2417beb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather10['Humidity'] = humidity\n",
    "weather10['Temp'] = temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c5e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff3aa81",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8950bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding discovery month as a feature for predictions\n",
    "DISCOVERY_MONTH = []\n",
    "for i in df['DISCOVERY_DATE']:\n",
    "    month = int(i.strftime(\"%Y-%m-%d\")[5:7])\n",
    "    DISCOVERY_MONTH.append(month)\n",
    "df['DISCOVERY_MONTH'] = DISCOVERY_MONTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532cb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing null values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfacd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'DISCOVERY_TIME': 'int64'}).copy()\n",
    "df = df.astype({'CONT_TIME': 'int64'}).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a234c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the Time features - removing incomplete rows that were not\n",
    "# 4 characters long\n",
    "def cleaner(x):\n",
    "    x=str(x)\n",
    "    if len(x)<3:\n",
    "        return '!'\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "df['DISCOVERY_TIME'] = df['DISCOVERY_TIME'].apply(cleaner).copy()\n",
    "df['CONT_TIME'] = df['CONT_TIME'].apply(cleaner).copy()\n",
    "\n",
    "df = df[df['DISCOVERY_TIME']!='!'].copy()\n",
    "df = df[df['CONT_TIME']!='!'].copy()\n",
    "\n",
    "def cleaner2(x):\n",
    "    try:\n",
    "        time = x[0]+x[1]+':'+x[2]+x[3]\n",
    "    except:\n",
    "        time = x[0]+':'+x[1]+x[2]\n",
    "    return time\n",
    "\n",
    "df['DISCOVERY_TIME'] = df['DISCOVERY_TIME'].apply(cleaner2).copy()\n",
    "df['CONT_TIME'] = df['CONT_TIME'].apply(cleaner2).copy()\n",
    "\n",
    "#Conversions of data type and creating one column combining \n",
    "# Date and Time\n",
    "\n",
    "df['DISCOVERY_DATE_AND_TIME'] = df['DISCOVERY_DATE'].astype(str).str.cat(df['DISCOVERY_TIME'].astype(str),sep=\" \")\n",
    "df['DISCOVERY_DATE_AND_TIME'] = pd.to_datetime(df['DISCOVERY_DATE_AND_TIME']).copy()\n",
    "\n",
    "df['CONT_DATE_AND_TIME'] = df['CONT_DATE'].astype(str).str.cat(df['CONT_TIME'].astype(str),sep=\" \")\n",
    "df['CONT_DATE_AND_TIME'] = pd.to_datetime(df['CONT_DATE_AND_TIME']).copy()\n",
    "\n",
    "#Creating the Duration Feature. This is the difference between when the\n",
    "#fire discovery date+time, and the contained date+time\n",
    "\n",
    "df['DURATION'] = df['CONT_DATE_AND_TIME'] - df['DISCOVERY_DATE_AND_TIME']\n",
    "\n",
    "def to_hours(x):\n",
    "    return x.total_seconds()/3600\n",
    "\n",
    "#conversion to hours\n",
    "df['DURATION'] = df['DURATION'].apply(to_hours).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a840338",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('wildfire_csv_withduration.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161aad14",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257327a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking Long, Lat\n",
    "#FOD_ID Unique identifier to make joining back to original DF easier\n",
    "outcodes = df[['FOD_ID','LATITUDE','LONGITUDE']].copy()\n",
    "outcodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e46423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = outcodes.head(30000).copy()\n",
    "\n",
    "#Building the distance_matrix for DBSCAN\n",
    "\n",
    "X['latitude_rad'] = X['LATITUDE']*np.pi/180\n",
    "X['longitude_rad'] = X['LONGITUDE']*np.pi/180\n",
    "distance_matrix = pairwise.haversine_distances(X.loc[:,\n",
    "['latitude_rad', 'longitude_rad']])*6371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27203ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=300, min_samples=2000, metric='precomputed')\n",
    "y_db = db.fit_predict(distance_matrix)  \n",
    "X['cluster'] = y_db\n",
    "X['cluster'] = X.cluster\n",
    "print(len(X.cluster.unique()))\n",
    "X.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(X['LONGITUDE'], X['LATITUDE'], c=X['cluster'],\n",
    "            cmap='spring', s=40)\n",
    "plt.xlabel('Longitude', fontsize=24)\n",
    "plt.ylabel('Latitude', fontsize=24)\n",
    "plt.title('DBScan clustering (3 clusters)', fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ec7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
